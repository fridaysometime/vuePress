# feature engineer

## 特征衍生（特征升维）

特征衍生一般是对原有的特征进行转换，计算以及组合而产生的新的特征。

1. 单一变量的基础转换，比如通过对单一变量进行平方，开根号，log转换，相乘，多变量的运算，比如两个变量相加，相乘或变量间计算一个比率后得到新变量等，目的是对非线性规律编码，有助于表示非线性关系。（特征组合形成了合成特征）

2. 变量通过添加时间维度进行衍生，比如3个月交易数据，6个月交易数据等。

   

## 特征筛选（特征降维）

1. 特征提取：是从原始特征中找出最有效的特征，这种做法的目的是降低数据冗余，减少模型计算，发现更有意义的特征等。

* 线性特征提取

  * 线性特征提取一般方法有PCA-主成分分析，LDA-线性判别分析，ICA-独立成分分析等

  * 非线性特征提取

2. 特征选择：从特征全集中产生出一个特征子集，筛选过程采用某种评价标准，把符合标准的特征筛选出来，同时对筛选出来的特征进行有效性验证。产生特征子集一般是一个搜索的过程，搜索空间中的每个状态就是一个特征子集，搜索算法分为完全搜索，启发式搜索和随机搜索。
3. 特征共线性分析

* 概念：多重共线性是指自变量之间存在一定程度的线性相关，会给变量对模型的贡献性带来影响。即若有两个变量存在共线性，在相互作用计算后，其一的变量的影响会相对减弱，而另一个变量的作用却会相对增强。
* 原因：比如没有足够多的样本数据；样本数据之间本身就客观存在共线性关系；
* 识别：系数估计值符号不对；删除某一个不太重要的特征，结果发生显著变化；统计学检验方法；
* 处理：增加样本数据量；stepwise结合主观分析，从少到多做特征选择；从共线性问题产生的自变量中删除一些不重要的变量

4. 信息熵，信息值，信息增益，gini指数，信息增益比：特征重要性；

   

